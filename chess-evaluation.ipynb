{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 14:35:05.599103: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-29 14:35:09.038336: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-10-29 14:35:09.038384: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-10-29 14:35:09.424962: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-29 14:35:13.784800: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-29 14:35:13.785527: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-29 14:35:13.785564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D, Concatenate, Input, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chessData = pd.read_csv('Data/chessData.csv')\n",
    "#random_evals = pd.read_csv('Data/random_evals.csv')\n",
    "tactic_evals = pd.read_csv('Data/tactic_evals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tactic_evals)\n",
    "tactic_evals = tactic_evals[:500000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4792/2706941485.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tactic_evals_check['isCheck'] = tactic_evals_check['Evaluation'].str.contains(\"#\")\n",
      "/tmp/ipykernel_4792/2706941485.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tactic_evals_check['isCheck'] = list(map(int, tactic_evals_check['isCheck']))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEN</th>\n",
       "      <th>Move</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2qkbr1/pb1nn3/1ppp3p/8/3P1p2/2PB1N1P/PPQN1PP1...</td>\n",
       "      <td>d3g6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2qkb2/pb1nn3/1ppp2rp/8/3P1p2/2P2N1P/PPQN1PP1/...</td>\n",
       "      <td>c2g6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2qkbr1/pb1nn3/1ppp2Bp/8/3P1p2/2P2N1P/PPQN1PP1...</td>\n",
       "      <td>g8g6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/7p/R5p1/2p1pkP1/7P/P4PK1/1r6/3q4 w - - 6 46</td>\n",
       "      <td>a6f6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6k1/pp6/3p4/2p1p3/2P1P1q1/1P1P2pP/P5P1/5K2 w -...</td>\n",
       "      <td>h3g4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 FEN  Move\n",
       "0  r2qkbr1/pb1nn3/1ppp3p/8/3P1p2/2PB1N1P/PPQN1PP1...  d3g6\n",
       "1  r2qkb2/pb1nn3/1ppp2rp/8/3P1p2/2P2N1P/PPQN1PP1/...  c2g6\n",
       "2  r2qkbr1/pb1nn3/1ppp2Bp/8/3P1p2/2P2N1P/PPQN1PP1...  g8g6\n",
       "3      8/7p/R5p1/2p1pkP1/7P/P4PK1/1r6/3q4 w - - 6 46  a6f6\n",
       "4  6k1/pp6/3p4/2p1p3/2P1P1q1/1P1P2pP/P5P1/5K2 w -...  h3g4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tactic_evals_check = tactic_evals.dropna()\n",
    "tactic_evals_check['isCheck'] = tactic_evals_check['Evaluation'].str.contains(\"#\")\n",
    "tactic_evals_check['isCheck'] = list(map(int, tactic_evals_check['isCheck']))\n",
    "\n",
    "predictors_raw = tactic_evals_check.drop(['Evaluation', 'isCheck'], axis=1)\n",
    "predictors_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_board(board):\n",
    "    return board.replace('/', ' ').split()\n",
    "\n",
    "def separate_move(move):\n",
    "    separated_move = []\n",
    "    for i in range(len(move)):\n",
    "        separated_move.append(move[i])\n",
    "    return separated_move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_lines = list(map(separate_board, np.asarray(tactic_evals_check['FEN'])))\n",
    "tokens_lines = [line[0:8] for line in tokens_lines]\n",
    "\n",
    "tokens_moves = list(map(separate_move, np.asarray(tactic_evals_check['Move'])))\n",
    "#tokens_piece = list(map(fen_to_tokens_without_spaces, np.asarray(tactic_evals['FEN'])))\n",
    "predictors_raw['FEN'] = tokens_lines\n",
    "predictors_raw['Move'] = tokens_moves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31168852, 37201280)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fen_embedding_dim = 32\n",
    "fen_embeddings = Word2Vec(sentences=tokens_lines, vector_size=fen_embedding_dim, window=5, min_count=1, sg=1)\n",
    "fen_embeddings.train(tokens_lines, total_examples=len(tokens_lines), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2647264, 18619900)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_embedding_dim = 32\n",
    "move_embeddings = Word2Vec(sentences=tokens_moves, vector_size=move_embedding_dim, window=5, min_count=1, sg=1)\n",
    "move_embeddings.train(tokens_moves, total_examples=len(tokens_moves), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fen_data = []\n",
    "move_data = []\n",
    "\n",
    "for line in range(len(tokens_lines)):\n",
    "    fen_data.append(fen_embeddings.wv[tokens_lines[line]])\n",
    "\n",
    "for move in range(len(tokens_moves)):\n",
    "    move_data.append(move_embeddings.wv[tokens_moves[move]])\n",
    "\n",
    "predictors = pd.DataFrame({\n",
    "    'fen_data': fen_data,\n",
    "    'move_data': move_data\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_data_expanded = []\n",
    "for embedding in move_data:\n",
    "    if embedding.shape == (4, 32):\n",
    "        move_data_expanded.append(np.vstack([embedding, np.zeros((4, 32))]))\n",
    "    else:\n",
    "        move_data_expanded.append(np.vstack([embedding, np.zeros((3, 32))]))\n",
    "        \n",
    "predictors['move_data'] = move_data_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fen_data_shape: (8, 32)\n",
      " move_data_shape: (8, 32)\n"
     ]
    }
   ],
   "source": [
    "print(f\"fen_data_shape: {predictors['fen_data'][0].shape}\\n move_data_shape: {predictors['move_data'][0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(465016, 8, 32)\n",
      "(465016, 8, 32)\n",
      "(465016, 8, 32, 1)\n",
      "(465016, 8, 32, 1)\n",
      "(465016,)\n"
     ]
    }
   ],
   "source": [
    "fen_data = np.array(predictors['fen_data'].tolist())\n",
    "move_data = np.array(predictors['move_data'].tolist()) \n",
    "\n",
    "\n",
    "print(fen_data.shape) \n",
    "print(move_data.shape) \n",
    "\n",
    "\n",
    "X_fen = np.reshape(fen_data, (fen_data.shape[0], 8, 32, 1)) \n",
    "X_move = np.reshape(move_data, (move_data.shape[0], 8, 32, 1)) \n",
    "\n",
    "y = tactic_evals_check['isCheck'].to_numpy()  \n",
    "\n",
    "\n",
    "print(X_fen.shape) \n",
    "print(X_move.shape)  \n",
    "print(y.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " fen_input (InputLayer)         [(None, 8, 32, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " move_input (InputLayer)        [(None, 8, 32, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 7, 31, 16)    80          ['fen_input[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 7, 31, 16)    80          ['move_input[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 3, 15, 16)   0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 3, 15, 16)   0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 720)          0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 720)          0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1440)         0           ['flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           46112       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            33          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 46,305\n",
      "Trainable params: 46,305\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ncols = predictors.shape[1]\n",
    "\n",
    "fen_input = Input(shape=(8, 32, 1), name='fen_input')\n",
    "move_input = Input(shape=(8, 32, 1), name='move_input')\n",
    "\n",
    "fen_conv1 = Conv2D(16, (2,2), activation='relu')(fen_input)\n",
    "move_conv1 = Conv2D(16, (2,2), activation='relu')(move_input)\n",
    "\n",
    "fen_mp1 = MaxPooling2D(pool_size=(2,2))(fen_conv1)\n",
    "move_mp1 = MaxPooling2D(pool_size=(2,2))(move_conv1)\n",
    "\n",
    "fen_flatter = Flatten()(fen_mp1)\n",
    "move_flatter = Flatten()(move_mp1)\n",
    "\n",
    "combined = Concatenate()([fen_flatter, move_flatter])\n",
    "\n",
    "dense = (Dense(32, activation = 'relu'))(combined)\n",
    "output = (Dense(1 , activation = 'sigmoid'))(dense)\n",
    "\n",
    "mate_evaluator = Model(inputs=[fen_input, move_input], outputs=output)\n",
    "mate_evaluator.compile(optimizer = 'adam', loss = 'binary_crossentropy', \n",
    "\t\t      metrics=['accuracy'])\n",
    "\n",
    "mate_evaluator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 14:45:55.521439: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 333323264 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10173/10173 [==============================] - 60s 6ms/step - loss: 0.2816 - accuracy: 0.8840 - val_loss: 0.2768 - val_accuracy: 0.8887\n",
      "Epoch 2/10\n",
      "10173/10173 [==============================] - 57s 6ms/step - loss: 0.2540 - accuracy: 0.8974 - val_loss: 0.2603 - val_accuracy: 0.8950\n",
      "Epoch 3/10\n",
      "10173/10173 [==============================] - 58s 6ms/step - loss: 0.2428 - accuracy: 0.9026 - val_loss: 0.2505 - val_accuracy: 0.8996\n",
      "Epoch 4/10\n",
      "10173/10173 [==============================] - 57s 6ms/step - loss: 0.2356 - accuracy: 0.9057 - val_loss: 0.2500 - val_accuracy: 0.9001\n",
      "Epoch 5/10\n",
      "10173/10173 [==============================] - 59s 6ms/step - loss: 0.2316 - accuracy: 0.9076 - val_loss: 0.2444 - val_accuracy: 0.9028\n",
      "Epoch 6/10\n",
      "10173/10173 [==============================] - 59s 6ms/step - loss: 0.2280 - accuracy: 0.9086 - val_loss: 0.2463 - val_accuracy: 0.9024\n",
      "Epoch 7/10\n",
      "10173/10173 [==============================] - 60s 6ms/step - loss: 0.2246 - accuracy: 0.9106 - val_loss: 0.2435 - val_accuracy: 0.9038\n",
      "Epoch 8/10\n",
      "10173/10173 [==============================] - 57s 6ms/step - loss: 0.2219 - accuracy: 0.9111 - val_loss: 0.2510 - val_accuracy: 0.8985\n",
      "Epoch 9/10\n",
      "10173/10173 [==============================] - 58s 6ms/step - loss: 0.2192 - accuracy: 0.9122 - val_loss: 0.2496 - val_accuracy: 0.9007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f305e5f69e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#acc = 0.8509\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "mate_evaluator.fit([X_fen, X_move], y, \n",
    "                    validation_split=0.3, \n",
    "                    epochs=10, \n",
    "                    callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'separate_board' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m test_match_board \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR3K1NR/PPPBBPPP/8/k7/3P2pp/p3P3/1pQ1p3/1r4nr\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m test_match_mate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2da5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m sep_board \u001b[38;5;241m=\u001b[39m \u001b[43mseparate_board\u001b[49m(test_match_board)\n\u001b[1;32m      5\u001b[0m sep_mate \u001b[38;5;241m=\u001b[39m separate_move(test_match_mate)\n\u001b[1;32m      8\u001b[0m board_emb \u001b[38;5;241m=\u001b[39m fen_embeddings\u001b[38;5;241m.\u001b[39mwv[sep_board]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'separate_board' is not defined"
     ]
    }
   ],
   "source": [
    "test_match_board = 'R3K1NR/PPPBBPPP/8/k7/3P2pp/p3P3/1pQ1p3/1r4nr'\n",
    "test_match_mate = '2da5'\n",
    "\n",
    "sep_board = separate_board(test_match_board)\n",
    "sep_mate = separate_move(test_match_mate)\n",
    "\n",
    "\n",
    "board_emb = fen_embeddings.wv[sep_board]\n",
    "mate_emb = move_embeddings.wv[sep_mate]\n",
    "\n",
    "print(board_emb.shape)\n",
    "print(mate_emb.shape)\n",
    "\n",
    "#mate_evaluator.predict([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
